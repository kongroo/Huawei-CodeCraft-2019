{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "%matplotlib inline\nfrom matplotlib import pyplot as plt\n\nimport os\nimport cv2\nimport string\nimport numpy as np\nfrom PIL import Image\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset", "execution_count": 1, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "import os\nhome_path = os.environ['HOME']+'/work/licence-plate' # \u8f93\u5165\u4e0b\u8f7d\u5230\u5bb9\u5668\u4e2d\u7684\u5730\u5740\uff0c\u5982home_path=os.environ['HOME']+'/work'\ndata_path = home_path + '/data'\n!mkdir -p $data_path\n\ndataset_url='https://codecraft-2019.obs.cn-north-1.myhuaweicloud.com/data/train-data.zip'\n\n!wget $dataset_url -O $data_path/train-data.zip -P $data_path \nimport zipfile\ndataset_file = data_path + '/train-data.zip'\nzip = zipfile.ZipFile(dataset_file)\nzip.extractall(data_path)\nzip.close()\n!rm -rf $dataset_file\n", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "--2019-04-18 09:21:25--  https://codecraft-2019.obs.cn-north-1.myhuaweicloud.com/data/train-data.zip\nResolving codecraft-2019.obs.cn-north-1.myhuaweicloud.com (codecraft-2019.obs.cn-north-1.myhuaweicloud.com)... 100.125.40.3, 100.125.40.34\nConnecting to codecraft-2019.obs.cn-north-1.myhuaweicloud.com (codecraft-2019.obs.cn-north-1.myhuaweicloud.com)|100.125.40.3|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 47549916 (45M) [application/zip]\nSaving to: \u2018/home/jovyan/work/licence-plate/data/train-data.zip\u2019\n\ntrain-data.zip      100%[===================>]  45.35M  44.8MB/s    in 1.0s    \n\n2019-04-18 09:21:26 (44.8 MB/s) - \u2018/home/jovyan/work/licence-plate/data/train-data.zip\u2019 saved [47549916/47549916]\n\n", "name": "stdout"}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "torch.manual_seed(2019)\nindex = {u'\u6df1':0, u'\u79e6':1, u'\u4eac':2, u'\u6d77':3, u'\u6210':4, u'\u5357':5, u'\u676d':6, u'\u82cf':7, u'\u677e':8}\nfor i, ch in enumerate(string.digits):\n    index[ch] = 9 + i \nfor i, ch in enumerate(string.ascii_uppercase):\n    index[ch] = 19 + i\nchars = [0] * 45\nfor ch, idx in index.items():\n    chars[idx] = ch", "execution_count": 3, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "class LicensePlateDataset(Dataset):\n    def __init__(self, root_dir):\n        self.root_dir = root_dir\n        self.labels = open(os.path.join(root_dir, 'train-data-label.txt'), encoding='utf-8').readlines()\n        self.labels = [line.split(',') for line in self.labels]\n        self.labels = [[img.strip(), label.strip()] for img, label in self.labels]\n        self.normalize = normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        self.transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            self.normalize,\n        ])\n\n    def __len__(self):\n        return len(self.labels)\n \n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir, 'train-data', self.labels[idx][1])\n        with Image.open(img_name) as img:\n            image = img.convert('RGB')\n        image = self.transform(image)\n        label = np.array([index[i] for i in self.labels[idx][0]])\n        label = torch.from_numpy(label)\n        #print(label)\n        return image, label", "execution_count": 4, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# def train(train_loader, model, criterion, optimizer, epoch):\n#     model.train()\n#     loss100 = 0.0\n#     for i, (input, target) in enumerate(train_loader):\n#         output = model(input)\n#         loss = criterion(output, target)\n#         optimizer.zero_grad()\n#         loss.backward()\n#         optimizer.step()\n#         loss100 += loss.item()\n#         if i % 100 == 99:\n#             print('[Epoch %d, Batch %5d] loss: %.3f' % (epoch + 1, i + 1, loss100 / 100))\n#             loss100 = 0.0", "execution_count": 5, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def accuracy(output, target):\n    #batch_size * num_class * num_label\n    #bath_size * num_label\n    num_label = 9\n    hit = 0.0\n    total = 0.0\n    with torch.no_grad():\n        batch_size = target.size(0)\n        pred = torch.argmax(output, dim=1)\n        hit = 1.0 * torch.sum(torch.eq(pred, target)).item()\n        total = 1.0 * batch_size * num_label\n    return 1.0 * hit / total", "execution_count": 6, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def validate(val_loader, model, criterion):\n    model.eval()\n    losses = 0.0\n    acc = 0.0\n    cnt = 0\n    with torch.no_grad():\n        for i, (input, target) in enumerate(val_loader):\n            input = input.cuda()\n            target = target.cuda()\n            cnt += 1\n            output = model(input)\n            output = output.view(-1, 45, 9)\n            loss = criterion(output, target)\n            losses += loss.item()\n            acc += accuracy(output, target)\n    print(\"loss : %f acc : %f\" % (losses, acc / cnt))", "execution_count": 7, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "lr = 0.001\nbatch_size = 128\nepochs = 10\nmodel = models.resnet50(num_classes=405)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr)\n# optimizer = torch.optim.SGD(model.parameters(), lr,\n#                                 momentum=0.9,\n#                                 weight_decay=0.0001)\nmodel.cuda()\ncriterion.cuda()\nroot_dir = 'work/licence-plate/data/'\ntrain_dataset = LicensePlateDataset(root_dir)\nval_dataset = LicensePlateDataset(root_dir)\ntrain_loader = torch.utils.data.DataLoader(\n    train_dataset, batch_size=batch_size, shuffle=True,\n    num_workers=0)\n\nval_loader = torch.utils.data.DataLoader(\n        val_dataset,\n        batch_size=batch_size, shuffle=False,\n        num_workers=0)", "execution_count": 8, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "for epoch in range(epochs):\n    #train(train_loader, model, criterion, optimizer, epoch)\n    model.train()\n    loss = 0.0\n    acc = 0.0\n    for i, (input, target) in enumerate(train_loader):\n#         print(input.shape)\n#         print(target.shape)\n#         #print(input, target)\n        input = input.cuda()\n        target = target.cuda()\n        output = model(input)\n        output = output.view(-1, 45, 9)\n        loss = criterion(output, target)\n        #print(target[0])\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        loss += loss.item()\n        acc += accuracy(output, target)\n        print('[Epoch %d, Batch %5d] loss: %.3f acc: %.3f' % (epoch + 1, i + 1, loss, acc))\n        loss = 0.0\n        acc = 0.0\n#torch.save(model, 'work/model.pkl')\ntorch.save(model.state_dict(), 'work/model-resnet50.pth')", "execution_count": null, "outputs": [{"output_type": "stream", "text": "[Epoch 1, Batch     1] loss: 8.173 acc: 0.015\n[Epoch 1, Batch     2] loss: 8.255 acc: 0.046\n[Epoch 1, Batch     3] loss: 8.368 acc: 0.048\n[Epoch 1, Batch     4] loss: 7.954 acc: 0.040\n[Epoch 1, Batch     5] loss: 7.924 acc: 0.057\n[Epoch 1, Batch     6] loss: 7.458 acc: 0.049\n[Epoch 1, Batch     7] loss: 7.464 acc: 0.043\n[Epoch 1, Batch     8] loss: 7.198 acc: 0.045\n[Epoch 1, Batch     9] loss: 7.161 acc: 0.040\n[Epoch 1, Batch    10] loss: 7.016 acc: 0.036\n[Epoch 1, Batch    11] loss: 6.842 acc: 0.053\n[Epoch 1, Batch    12] loss: 6.947 acc: 0.042\n[Epoch 1, Batch    13] loss: 6.951 acc: 0.054\n[Epoch 1, Batch    14] loss: 6.897 acc: 0.032\n[Epoch 1, Batch    15] loss: 6.842 acc: 0.043\n[Epoch 1, Batch    16] loss: 7.131 acc: 0.049\n[Epoch 1, Batch    17] loss: 6.852 acc: 0.042\n[Epoch 1, Batch    18] loss: 6.855 acc: 0.042\n[Epoch 1, Batch    19] loss: 6.740 acc: 0.057\n[Epoch 1, Batch    20] loss: 6.825 acc: 0.041\n[Epoch 1, Batch    21] loss: 6.759 acc: 0.051\n[Epoch 1, Batch    22] loss: 6.810 acc: 0.042\n[Epoch 1, Batch    23] loss: 6.799 acc: 0.046\n[Epoch 1, Batch    24] loss: 6.721 acc: 0.047\n[Epoch 1, Batch    25] loss: 6.769 acc: 0.046\n[Epoch 1, Batch    26] loss: 6.704 acc: 0.049\n[Epoch 1, Batch    27] loss: 6.755 acc: 0.037\n[Epoch 1, Batch    28] loss: 6.694 acc: 0.046\n[Epoch 1, Batch    29] loss: 6.736 acc: 0.042\n[Epoch 1, Batch    30] loss: 6.719 acc: 0.049\n[Epoch 1, Batch    31] loss: 6.704 acc: 0.051\n[Epoch 1, Batch    32] loss: 6.668 acc: 0.059\n[Epoch 2, Batch     1] loss: 6.662 acc: 0.055\n[Epoch 2, Batch     2] loss: 6.678 acc: 0.055\n[Epoch 2, Batch     3] loss: 6.663 acc: 0.049\n[Epoch 2, Batch     4] loss: 6.689 acc: 0.057\n[Epoch 2, Batch     5] loss: 6.684 acc: 0.039\n[Epoch 2, Batch     6] loss: 6.689 acc: 0.043\n[Epoch 2, Batch     7] loss: 6.733 acc: 0.045\n[Epoch 2, Batch     8] loss: 6.716 acc: 0.048\n[Epoch 2, Batch     9] loss: 6.690 acc: 0.056\n[Epoch 2, Batch    10] loss: 6.690 acc: 0.043\n", "name": "stdout"}]}, {"metadata": {"scrolled": true, "trusted": true}, "cell_type": "code", "source": "validate(val_loader, model, criterion)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "image_name = 'work/licence-plate/data/train-data/2c9ec2debce77459.jpg'\nimage = np.asarray(bytearray(open(image_name, 'rb').read()), dtype=\"uint8\")\n\nbin_file = cv2.imdecode(image, cv2.IMREAD_COLOR)\n\nimg = cv2.imread(image_name)\n#plt.imshow(img)\nplt.imshow(bin_file)\n\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\ntransform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n            normalize,\n        ])\nwith Image.open(image_name) as img:\n   image = img.convert('RGB')\n    \n# image = Image.fromarray(cv2.cvtColor(bin_file,cv2.COLOR_BGR2RGB))  \n# image = image.convert('RGB')\n\nimage = transform(image)\nimage = image[None]\ninputs = image.cuda()\noutput = model(inputs)\noutput = output.view(45, 9)\nmm = torch.argmax(output, dim=0)\nprint([chars[i] for i in mm])", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# resnet50 = models.resnet50(pretrained=True)\n# !ls work", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# img = cv2.imread('2b6b3180b74c55b0.jpg')\n# img = cv2.resize(img, (224,224))\n# plt.imshow(img)\n\n\n# image = transforms.ToTensor()(img)\n# image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n# image = image[None]\n# inputs = Variable(image)\n# output = resnet50(inputs)\n# torch.argmax(output)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# #\u4fee\u6539\u5206\u7c7b\u7684\u6570\u91cf\u4e3a2\n# num_ftrs = resnet50.fc.in_features\n# resnet50.fc = nn.Linear(num_ftrs, 44 * 9)\n\n\n# img = cv2.imread('/bigdata/gemfield/github/data/val/1/img_0.jpg')\n# img = cv2.resize(img, (224,224))\n# image = transforms.ToTensor()(img)\n# image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n# image = image[None]\n# inputs = Variable(image.cuda())\n# output = resnet50(inputs)\n\n# outputs = torch.stack([nn.Softmax(dim=0)(i) for i in output])\n# outputs = outputs.mean(0)\n# p, preds = torch.max(outputs, 0)\n\n# # tensor -> scaler\n# print(p.data.cpu().item())\n# print(preds.data.cpu().item())", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# model = torch.load(model.pkl')\n# img = cv2.imread('/bigdata/gemfield/github/data/val/1/img_0.jpg')\n# img = cv2.resize(img, (224,224))\n# image = transforms.ToTensor()(img)\n# image = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(image)\n# image = image[None]\n# inputs = Variable(image\n# output = model(inputs)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# torch.manual_seed(20)\n# loss = nn.CrossEntropyLoss()\n# input = torch.randn(3, 5, 2,requires_grad=True)\n# target = torch.empty(3, 2, dtype=torch.long).random_(5)\n# print(input)\n# print(target)\n# output = loss(input, target)\n# output.backward()\n# print(output.item())\n# output = loss(input[:,:,0], target[:,0])\n# output.backward()\n# print(output.item())\n# output = loss(input[:,:,1], target[:,1])\n# output.backward()\n# print(output.item())\n# print(target.size(0))\n# mm = torch.argmax(input, dim=1)\n# a = torch.eq(mm, target)\n# print(a)\n# print(target.size())\n# accuracy(input, target)", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}